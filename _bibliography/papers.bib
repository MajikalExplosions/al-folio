---
---

@string{aps = {American Physical Society,}}

@inproceedings{j2025text,
abbr={In Preparation},
bibtex_show = {false},
title={Judging Text Simplicity with Large Language Models},
author={Joseph Liu and Xinyue Cui and Yoonsoo Nam and Swabha Swayamdipta},
booktitle={preparation for ACL submission},
year={2024},
month={dec},
url={https://joseph.liu.us/r/text},
pdf={https://joseph.liu.us/assets/pdf/2024-1201-Text-Simp.pdf},
abstract={Existing text simplification metrics face challenges ranging from limited datasets to a reliance on references. To address this, we propose a Panel of Language Models as a reference-free metric that removes the need for extensive training data. The panel uses exclusively pretrained language models and therefore benefits from their extensive dataset, deeper understanding of language, and potential future advances. We show that this metric is competitive with, and in some cases outperforms, existing metrics in human correlation. Furthermore, we find that it is more consistent than even human annotators in scoring simplification quality on certain dimensions.},
}

@inproceedings{jiaqi2025symbolic,
abbr={CVPR},
bibtex_show = {false},
title={Symbolic Representation for Any-to-Any Generative Tasks},
author={Jiaqi Chen and Xiaoye Zhu and Yue Wang and Tianyang Liu and Xinhui Chen and Ying Chen and Chak Tou Leong and Yifei Ke and Joseph Liu and Yiwen Yuan and Julian McAuley and Li-jia Li},
booktitle={CVPR 2025},
year={2025},
month={jun},
url={https://joseph.liu.us/r/cvpr},
location={Nashville, TN, USA},
pdf={https://joseph.liu.us/assets/pdf/2024-1100-Symbolic-Representation.pdf},
abstract={We propose a symbolic generative task descriptive language and inference engine, capable of representing arbitrary multimodal tasks as symbolic flows. The inference engine maps natural language instructions to symbolic flow, eliminating the need for task-specific training. Conventional generative models rely heavily on large-scale training and implicit neural representation to learn cross-modal mappings, which demands extensive computational resources and restricts expandability. In this paper, we propose an explicit symbolic task descriptive language, comprising three types of primitives: functions, parameters, and topological logic. Using a pre-trained language model to infer symbolic workflows in a training-free manner, our framework successfully performs over 12 multimodal generative tasks based on user instructions, demonstrating enhanced efficiency and flexibility. Extensive experiments demonstrate that our approach can generate multimodal content competitive with, and often surpassing, that of previous state-ofthe-art unified models, while offering robust interruptibility and editability. We believe that symbolic task representations are capable of cost-effectively expanding the boundaries of generative AI capabilities. All code and results are available in the Supplementary Materials.},
}

@inproceedings{xinhui2024generative,
abbr={NeurIPS Workshop},
selected={true},
bibtex_show = {false},
title={Generative Models in Protein Engineering: A Comprehensive Survey},
author={Chen Xinhui* and Yiwen Yuan* and Joseph Liu* and Chak Tou Leong and Xiaoye Zhu and Jiaqi Chen},
booktitle={Neurips 2024 Workshop Foundation Models for Science: Progress, Opportunities, and Challenges},
year={2024},
month={dec},
url={https://openreview.net/forum?id=Xc7l84S0Ao},
location={Vancouver, BC, Canada},
pdf={https://joseph.liu.us/assets/pdf/2024-1018-NeurIPS-Protein.pdf},
abstract={Proteins are fundamental molecules performing diverse functions in living organisms. Protein engineering, the process of designing or modifying proteins to enhance or create new functions, has therefore become a research focus in the fields of biotechnology and medicine. A primary challenge in protein engineering is to efficiently discover and design new proteins with desired functions. Traditional approaches like directed evolution and rational design, though widely used, are limited by high computational costs and restricted exploration of potential protein structures. The recent success of generative models in efficiently synthesizing high-quality data across various domains has inspired researchers to investigate their potential applications in protein engineering. In this survey, we systematically summarize recent works on generative models for protein engineering, with a particular focus on protein design. Specifically, we categorize three main frameworks in existing generative protein design methods: sequence-based, structure-based, and joint sequence-structure generation. Besides, we provide a detailed review of representative generative models, including autoregressive models and diffusion models, and their application in protein sequence prediction and structure generation. Finally, we pinpoint existing challenges and propose future directions, such as leveraging large datasets, improving complex structure validation, and integrating advanced modeling techniques.},
award_name={Poster},
award={Poster presentation}
}

@article{Smith_2024,
abbr = {APJ},
selected = {true},
bibtex_show = {false},
dimensions = {false},
altmetric = {false},
google_scholar_id_disable = {u5HHmVD_uO8C},
doi = {10.3847/1538-4357/ad6eff},
html = {https://dx.doi.org/10.3847/1538-4357/ad6eff},
year = {2024},
month = {oct},
url = {https://dx.doi.org/10.3847/1538-4357/ad6eff},
publisher = {The American Astronomical Society},
volume = {974},
number = {2},
pages = {292},
author = {Richard Smith and Avi Patel and Monika D. Soraisam and Puragra Guhathakurta and Pranav Tadepalli and Sally Zhu and Joseph Liu and Léo Girardi and L. Clifton Johnson and Sagnick Mukherjee and Knut A. G. Olsen and Benjamin F. Williams},
title = {Variable Stars in M31 Stellar Clusters from the Panchromatic Hubble Andromeda Treasury},
journal = {The Astrophysical Journal},
abstract = {Variable stars in stellar clusters can offer key constraints on stellar evolution and pulsation models, utilizing estimates of host cluster properties to constrain stellar physical parameters. We present a catalog of 86 luminous (F814W &lt; 19) variable stars in M31 clusters identified by mining the archival Panchromatic Hubble Andromeda Treasury (PHAT) survey using a combination of statistical analysis of sparse PHAT light curves and difference imaging. We determine the evolutionary phases and initial masses of these variable stars by matching them with theoretical isochrones generated using host cluster properties from the literature. We calculate the probability of PHAT photometry being blended due to the highly crowded nature of cluster environments for each cluster-variable star, using these probabilities to inform our level of confidence in the derived properties of each star. Our 86 cluster-variable stars have initial masses between 0.8 and 67 M ⊙. Their evolutionary phases span the main sequence, more evolved hydrogen- and helium-burning phases, and the post–asymptotic giant branch. We identify numerous candidate variable star types: RV Tauri variables, red supergiants, and slowly pulsating B-type supergiants, along with Wolf–Rayet stars, α Cygni and Mira variables, a classical Cepheid, and a possible superasymptotic giant. We characterize 12 cluster-variable stars at higher confidence based on their difference image quality and lower blending probability. Ours is the first systematic study of variable stars in extragalactic stellar clusters leveraging the superior resolution of the Hubble Space Telescope and demonstrating the unique power of stellar clusters in constraining the fundamental properties of variable stars.}
}

@techreport{he_2023_enhancing,
  abbr = {Tech Report},
  bibtex_show = {false},
  author = {He*, Keyu and Li*, Max and Liu*, Joseph},
  year = {2023},
  month = {12},
  title = {Enhancing Debugging Skills of LLMs with Prompt Engineering},
  url = {https://joseph.liu.us/assets/pdf/2023-1211-Enhancing-Debugging.pdf},
  pdf = {https://joseph.liu.us/assets/pdf/2023-1211-Enhancing-Debugging.pdf},
  urldate = {2023-12-11},
  abstract = {This paper presents a comprehensive study on improving the debugging capabilities of Large Language Models (LLMs) like GPT-3.5, focusing on the application of prompt engineering techniques. We explore the efficacy of few-shot learning, chain-of-thought prompting, and a baseline zero-shot model in enhancing LLMs’ ability to debug code. Utilizing static and dynamic evaluation metrics, the study rigorously assesses the debugging proficiency of these models. By introducing different types of bugs, including procedural and language model-generated errors, and applying varied prompting strategies, we provide a deeper understanding of LLMs’ debugging capabilities. The results provide insights into the limitation of debugging capabilities of GPT-3.5 Turbo, even with the assistance of various prompting techniques. Source code of our evaluation method and bug generation techniques are in <a href="https://github.com/FrankHe2002/CSCI499FinalProject">GitHub repository</a>. },
}

@techreport{liu_2023_predicting,
  abbr = {Tech Report},
  bibtex_show = {false},
  author = {Liu, Joseph},
  year = {2023},
  month = {05},
  title = {Predicting Game Popularity from Steam Descriptions},
  url = {https://joseph.liu.us/assets/pdf/2023-0501-Predicting-Game-Popularity.pdf},
  pdf = {https://joseph.liu.us/assets/pdf/2023-0501-Predicting-Game-Popularity.pdf},
  urldate = {2023-05-01},
  abstract = {In many cases, game descriptions are some of the f irst places where potential players learn about games. Therefore, it is imperative that publishers and developers write interesting descriptions that positively impact sales. In this project, we investigate the correlation between game descriptions and game popularity, independent from gameplay, using various models. We begin with a classification problem, including our baseline, Softmax Regression and our best model, Bidirectional RNN, and also experiment with different data representations and eventually regression. We conclude that while much of a game’s popularity is associated with gameplay, the description also has a non-negligible impact on popularity. <a href="https://github.com/jliu7350/csci467_final_project">GitHub repository</a>.},
}

@article{Patel2022Variable,
  abbr = {Bulletin of the AAS},
  bibtex_show = {false},
	author = {Patel, Avi and Mukherjee, Sagnick and Soraisam, Monika and Guhathakurta, Puragra and Liu, Joseph and Tadepalli, Pranav},
	journal = {Bulletin of the AAS},
	number = {6},
	year = {2022},
	month = {jun 29},
	url = {https://baas.aas.org/pub/2022n6i201p02},
	html = {https://baas.aas.org/pub/2022n6i201p02},
	publisher = {},
	title = {Variable {Stars} in {M31} {Stellar} {Clusters} using the {Panchromatic} {Hubble} {Andromeda} {Treasury}},
	volume = {54},
}
